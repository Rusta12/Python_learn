BeautifulSoup ::::::::::::::::::::::::::::::::::::::::::::::::::::::

# это парсер для синтаксического разбора файлов HTML/XML, написанный 
# на языке программирования Python, который может преобразовать даже 
# неправильную разметку в дерево синтаксического разбора. Он 
# поддерживает простые и естественные способы навигации, поиска и 
# модификации дерева синтаксического разбора. 

# документация на английском:
# https://www.crummy.com/software/BeautifulSoup/bs4/doc/

# документация на русском:
# http://wiki.python.su/Документации/BeautifulSoup

# установка
pip install beautifulsoup4
# для парсинга XML
pip install lxml
# для парсинга HTML5
pip install html5lib

# ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

from bs4 import (
	BeautifulSoup, CData, NavigableString, Comment
)

bs = bs4.BeautifulSoup('example.html', 'html.parser' from_encoding)
# получение объекта BeautifulSoup, для того чтобы можно было 
# использовать его методы для поиска отдельных частей HTML-документа
	from_encoding
	# указывает кодировку
	exclude_encodings
	# исключить кодировку


# ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

bs.h2
# получение первого тега <h2></h2>.(Объект тега). Так можно 
# обращаться и к title, body, footer

	.name
	# название тега

	['class']
	# получение значений атрибутов с помощью css-селекторов

	.attrs
	# получение атрибутов тега в виде словаря

	.get('id')
	# получение значения атрибута, в отличии от обращения напримую, в
	# случае отсутствия атрибута возвращает None, а не KeyError

	.string
	# возвращает содержимое тега

		.parent
		# получение родителя строки

	.get_text()
	# возвращает весь текст в документе или под тегом как одну 
	# строку Unicode

	.prettify(formatter="minimal")
	# форматирует HTML для удобочитаемости
		"minimal"
		# установлен по умолчанию стандартное форматирование для 
		# удобного чтения HTML
		"html"
		# BeautifulSoup будет конвертировать символы Unicode в 
		# HTML-объекты по возможности
		None
		# BeautifulSoup не будет изменять строки вообще на выходе. 
		# Это самый быстрый вариант, но это может привести к тому, 
		# что Beautiful Soup создаст неверный HTML/XML
		uppercase
		# преобразование строкового содержимого в верхний регистр


	.contents
	# получение списка всех дочерних элементов

	.children
	# получение гениратора дочерних элементов

	.descendants
	# позволяет перебирать все дочерние элементы тега, рекурсивно: 
	# его прямые дети, дети его прямых детей и т.д.

	.stripped_strings
	# строки имеют много лишних пробелов, которые можно удалить, 
	# используя генератор строк .stripped_strings

	.parent
	# получение родительского элемента

	.parents
	# получение всех родителей тега (сначало родителя, потом родителя
	# родителя и т.д.)

	.next_sibling
	# следующий тег, рядом с данным тегом

	.previous_sibling
	# предыдущий тег, рядом с данным тегом

	.next_element
	# он указывает на то, какой элемент был проанализирован 
	# непосредственно после

	.previous_element
	# полная противоположность .next_element. Он указывает на то, 
	# какой элемент был проанализирован непосредственно перед этим

	.has_attr('class')
	# проверка на наличие атрибутов

	.find_parents(name, attrs, string, limit, **kwargs)
	# поиск и получения списка радителей

	.find_parent(name, attrs, string, **kwargs)
	# поиск и получение родителя

	.find_next_siblings(name, attrs, string, limit, **kwargs)
	# ищет и возвращает список следующих тегов рядом с данным тегом

	.find_next_sibling(name, attrs, string, **kwargs)
	# ищет и возвращает следующий тег рядом с данным тегом

	.find_previous_siblings(name, attrs, string, limit, **kwargs)
	# ищет и возвращает список предыдущих тегов рядом с данным
	# тегом

	.find_previous_sibling(name, attrs, string, **kwargs)
	# ищет и возвращает предыдущий тег рядом с данным тегом

	.find_all_next(name, attrs, string, limit, **kwargs)
	# он использует функцию next_element при поиске и возвращает
	# список найденных элементов

	.find_next(name, attrs, string, **kwargs)
	# вернёт первый найденный элемент

	.find_all_previous(name, attrs, string, limit, **kwargs)
	# тоже самое что и find_all_next только ищет предыдущие

	.find_previous(name, attrs, string, **kwargs)
	# тоже самое что и find_next только ищет предыдущий

	.append(content)
	# вставляет содержимое в тег сразу после существующего 
	# содержимого

	.insert(num, text)
	# вставка контента в определённую позицию

	.insert_before(content)
	# вставка контента до

	.insert_after(content)
	# вставка контента после

	.clear()
	# очистка содержимого тега

	.extract()
	# верезает контент к которому он пременяется, после данного 
	# метода у контента не будет родителей

	.decompose()
	# удаляет контент и содержимое к которому он применяется

	.replace_wit(text)
	# удаляет тег или строку из дерева и заменяет его тегом 
	# или строкой по вашему выбору

	.wrap(tag)
	# оборачивает содержимое или тег новым тегом

	.unwrap()
	# удаляет обёртку тега или обёртку содержимого тега

	.encode('utf-8')
	# получение контента в кодировке utf-8



del bs.img['id']
# удаление атрибутов

bs.find(id='ex')
# поиск тега, можно использовать css-селекторы или вместе

bs.find_all(name, attrs, recursive, string, limit, **kwargs)
# поиск и получение списка найденных элементов, можно искать
# с помощью регулярок, сразу список элементов, можно передать
# True он найдёт все теги.

bs.select('p #author')
# возвращает список объектов Tag, предоставляющий в BeautifulSoup
# HTML-элементы. Поиск с помощью гибкости css-селекторов

bs.select_one(css_selector)
# поиск первого тега соответствующего селектору

bs.new_tag("a", href="http://www.example.com")
# создаёт новый тег

bs.stripped_strings
#

bs.original_encoding
# автоопределение кодировки



NavigableString('example text')
# конструктор контента, который затем можно вставить в тег

Comment('this comment')
# конструктор комментария, который затем можно вставить в 
# документ