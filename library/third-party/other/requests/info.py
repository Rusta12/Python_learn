import requests

# упращает загрузку файлов из интернета, позволяя не задумываться
# о таких сложных вопросах, как ошибки сети, проблемы подключения
# сжатия данных

# :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

res = requests.get(url)
# принимает строку с url-адресом по которому должна 
# осуществляться загрузка

requests.post(url, data={'key':'value'})
#

requests.put(url, data={'key':'value'})
#

requests.delete(url)
#

requests.head(url)
#

requests.options(url)
#

res.status_code == requests.codes.ok # True
# проверка успешности выполнения запроса

res.text
# в случае успешного выполнения запроса загруженная страница
# сохраняется в виде строки в переменной text

res.headers['content-type']
# получение заголовкоа

res.raise_for_status()
# возбуждает исключение, если в процессе обработки запроса 
# произашла ошибка, и не совершает не каких действий в случае
# успешной загрузки

res.iter_content(100000)
# возвращает порции содердимого на каждой стадии цикла.
# Каждая порция данных - это данные байтового типа, можно 
# указать сколько байтов должна содержать каждая порция


# :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

# TODO: дописать документацию
# TODO: изменить архитектуру документации
# TODO: прописать пути к документации